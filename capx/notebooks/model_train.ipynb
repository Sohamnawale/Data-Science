{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iv92jlEMcxiE"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "def pos_tagging(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    tags = pos_tag(tokens)\n",
        "    return [tag for word, tag in tags]\n",
        "\n",
        "data['pos_tags'] = data['cleaned_message'].apply(lambda x: pos_tagging(x))\n",
        "\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=2000, ngram_range=(1, 2), stop_words='english')\n",
        "tfidf_features = tfidf_vectorizer.fit_transform(data['cleaned_message']).toarray()\n",
        "\n",
        "\n",
        "data['word_count'] = data['cleaned_message'].apply(lambda x: len(x.split()))\n",
        "data['contains_numbers'] = data['cleaned_message'].apply(lambda x: int(any(c.isdigit() for c in x)))\n",
        "\n",
        "feature_df = pd.DataFrame(tfidf_features, columns=tfidf_vectorizer.get_feature_names_out())\n",
        "feature_df['word_count'] = data['word_count']\n",
        "feature_df['contains_numbers'] = data['contains_numbers']\n",
        "\n",
        "\n",
        "feature_df['sentiment'] = data['sentiment']\n",
        "feature_df['hour'] = data['hour']\n",
        "feature_df['day_of_week'] = data['day_of_week']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(feature_df)\n",
        "\n",
        "\n",
        "np.random.seed(42)\n",
        "feature_df['stock_movement'] = np.random.choice([0, 1], size=len(feature_df))\n",
        "\n",
        "\n",
        "X = feature_df.drop('stock_movement', axis=1)\n",
        "y = feature_df['stock_movement']\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score\n",
        "\n",
        "lgbm_model = lgb.LGBMClassifier(boosting_type='gbdt', num_leaves=31, learning_rate=0.1, n_estimators=100)\n",
        "lgbm_model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = lgbm_model.predict(X_test)\n",
        "y_prob = lgbm_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"ROC AUC: {roc_auc:.2f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Down', 'Up'], yticklabels=['Down', 'Up'])\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "\n",
        "param_dist = {\n",
        "    'num_leaves': [31, 40, 50],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'subsample': [0.6, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
        "}\n",
        "\n",
        "\n",
        "random_search = RandomizedSearchCV(estimator=lgb.LGBMClassifier(), param_distributions=param_dist, n_iter=50, cv=3, scoring='accuracy', random_state=42, n_jobs=-1)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", random_search.best_params_)\n",
        "\n",
        "# Evaluate the best model\n",
        "best_lgbm_model = random_search.best_estimator_\n",
        "y_pred_best = best_lgbm_model.predict(X_test)\n",
        "\n",
        "# Accuracy and other metrics for the best model\n",
        "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
        "print(\"Improved Accuracy:\", accuracy_best)\n"
      ]
    }
  ]
}